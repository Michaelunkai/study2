### Step 14: Time Series Forecasting with LSTM

1. **Install Required Libraries:**

     
   pip install tensorflow pandas

2. **Create a New Python Script:**
   Create a script for time series forecasting using LSTM. Name it `lstm_time_series.py`.

     
   nano lstm_time_series.py

3. **Write the Following Code in the Script:**

     
   import pandas as pd
   import numpy as np
   import tensorflow as tf
   from sklearn.preprocessing import MinMaxScaler
   import matplotlib.pyplot as plt

   # Load the dataset
   data = pd.read_csv('time_series_data.csv', date_parser=True)  # Replace with your time series data
   data = data['value']  # Assuming 'value' column contains the time series data

   # Prepare the data
   scaler = MinMaxScaler(feature_range=(0, 1))
   data = scaler.fit_transform(np.array(data).reshape(-1, 1))

   # Split the data into training and testing sets
   training_size = int(len(data) * 0.65)
   test_size = len(data) - training_size
   train_data, test_data = data[0:training_size, :], data[training_size:len(data), :1]

   # Convert an array of values into a dataset matrix
   def create_dataset(dataset, time_step=1):
       dataX, dataY = [], []
       for i in range(len(dataset) - time_step - 1):
           a = dataset[i:(i + time_step), 0]
           dataX.append(a)
           dataY.append(dataset[i + time_step, 0])
       return np.array(dataX), np.array(dataY)

   time_step = 100
   X_train, y_train = create_dataset(train_data, time_step)
   X_test, y_test = create_dataset(test_data, time_step)

   # Reshape input to be [samples, time steps, features] which is required for LSTM
   X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
   X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

   # Create the LSTM model
   model = tf.keras.models.Sequential()
   model.add(tf.keras.layers.LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
   model.add(tf.keras.layers.LSTM(50, return_sequences=False))
   model.add(tf.keras.layers.Dense(25))
   model.add(tf.keras.layers.Dense(1))

   # Compile the model
   model.compile(optimizer='adam', loss='mean_squared_error')

   # Train the model
   model.fit(X_train, y_train, batch_size=1, epochs=1)

   # Make predictions
   train_predict = model.predict(X_train)
   test_predict = model.predict(X_test)

   # Transform back to original form
   train_predict = scaler.inverse_transform(train_predict)
   test_predict = scaler.inverse_transform(test_predict)

   # Calculate RMSE
   train_rmse = np.sqrt(np.mean(((train_predict - scaler.inverse_transform(y_train.reshape(-1, 1))) ** 2)))
   test_rmse = np.sqrt(np.mean(((test_predict - scaler.inverse_transform(y_test.reshape(-1, 1))) ** 2)))
   print(f'Train RMSE: {train_rmse}')
   print(f'Test RMSE: {test_rmse}')

   # Plot the results
   plt.figure(figsize=(8, 4))
   plt.plot(scaler.inverse_transform(data), label='Original Data')
   plt.plot(np.arange(time_step, len(train_predict) + time_step), train_predict, label='Train Prediction')
   plt.plot(np.arange(len(train_predict) + (time_step * 2) + 1, len(data) - 1), test_predict, label='Test Prediction')
   plt.legend()
   plt. ow()

4. **Run the Script:**

     
     lstm_time_series.py

### Explanation of Output:

- **Train RMSE**: Shows the Root Mean Square Error for the training set.
- **Test RMSE**: Shows the Root Mean Square Error for the test set.
- **Plot**: Visual representation comparing original data and predictions.

### Step 15: Clustering with K-Means

1. **Install Required Libraries:**

     
   pip install scikit-learn matplotlib

2. **Create a New Python Script:**
   Create a script for performing K-Means clustering. Name it `kmeans_clustering.py`.

     
   nano kmeans_clustering.py

3. **Write the Following Code in the Script:**

     
   import pandas as pd
   import numpy as np
   from sklearn.datasets import make_blobs
   from sklearn.cluster import KMeans
   import matplotlib.pyplot as plt

   # Generate sample data
   X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)

   # Fit K-Means clustering model
   kmeans = KMeans(n_clusters=4)
   kmeans.fit(X)
   y_kmeans = kmeans.predict(X)

   # Plot the results
   plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')

   centers = kmeans.cluster_centers_
   plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75)
   plt. ow()

4. **Run the Script:**

     
     kmeans_clustering.py

### Explanation of Output:

- **Cluster Plot**: Visual representation of data points colored by their cluster assignment.
- **Cluster Centers**: Red dots representing the centroids of the clusters.

### Step 16: Dimensionality Reduction with PCA

1. **Install Required Libraries:**

     
   pip install scikit-learn matplotlib

2. **Create a New Python Script:**
   Create a script for performing PCA. Name it `pca_dimensionality_reduction.py`.

     
   nano pca_dimensionality_reduction.py

3. **Write the Following Code in the Script:**

     
   import pandas as pd
   import numpy as np
   from sklearn.datasets import load_iris
   from sklearn.decomposition import PCA
   import matplotlib.pyplot as plt

   # Load the Iris dataset
   iris = load_iris()
   X = iris.data
   y = iris.target

   # Apply PCA
   pca = PCA(n_components=2)
   principalComponents = pca.fit_transform(X)
   principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2'])

   finalDf = pd.concat([principalDf, pd.DataFrame(y, columns=['target'])], axis=1)

   # Plot the results
   plt.figure(figsize=(8, 6))
   plt.scatter(finalDf['principal component 1'], finalDf['principal component 2'], c=finalDf['target'], cmap='viridis')
   plt.xlabel('Principal Component 1')
   plt.ylabel('Principal Component 2')
   plt. ow()

4. **Run the Script:**

     
     pca_dimensionality_reduction.py

### Explanation of Output:

- **PCA Plot**: Visual representation of data points in reduced dimensions (2D) colored by their target class.

These advanced steps cover time series forecasting with LSTM, K-Means clustering, and PCA for dimensionality reduction. Let me know if you have any questions or if you're ready to continue!
