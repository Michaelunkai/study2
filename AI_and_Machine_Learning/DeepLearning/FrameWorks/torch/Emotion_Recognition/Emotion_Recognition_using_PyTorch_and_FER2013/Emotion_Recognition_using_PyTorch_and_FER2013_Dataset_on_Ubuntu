# Comprehensive Tutorial: Emotion Recognition using PyTorch and FER2013 Dataset on Ubuntu

In this comprehensive tutorial, we will guide you through the process of building an emotion recognition system using PyTorch, the FER2013 dataset, and Ubuntu. We will cover data preprocessing, model building, training, and evaluation. Let's get started!

## Step 1: Install Required Software

1. **Install Ubuntu**: If you haven't already, install Ubuntu on your machine.

2. **Install Python and PyTorch**:
      
    sudo apt update
    sudo apt install python3 python3-pip
    pip3 install torch torchvision torchaudio

3. **Install Additional Libraries**:
      
    pip3 install opencv-python matplotlib pillow pandas

## Step 2: Prepare the Dataset

1. **Download the Dataset**:
    - The FER2013 dataset should already be in the directory `/root/fer2013`.

2. **Preprocess the Dataset**:
    - The FER2013 dataset is in a CSV file format. You need to convert it to images.
    - Create a file named `convert_fer2013_to_images.py` using the `nano` command:

      
    nano convert_fer2013_to_images.py

    - Add the following script to the file:

      
    import pandas as pd
    import numpy as np
    import os
    from PIL import Image

    def convert_fer2013_to_images( _path, output_dir):
        df = pd.read_ ( _path)
        emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        for index, row in df.iterrows():
            emotion = emotions[row['emotion']]
            pixels = np.array(row['pixels'].split(' '), dtype=int).reshape(48, 48)
            img = Image.fromarray(pixels.astype('uint8'))
            img_path = os.path.join(output_dir, f"{emotion}_{index}.jpg")
            img.save(img_path)

     _path = '/root/fer2013/fer2013. '
    output_dir = '/root/fer2013/images'
    convert_fer2013_to_images( _path, output_dir)

    - Save and exit the file using `Ctrl+X`, then `Y`, and `Enter`.

    - Run the script:

      
     3 convert_fer2013_to_images.py

## Step 3: Build the Model

1. **Define the Model**:
    - We'll use a simple Convolutional Neural Network (CNN) for this task.
    - Create a file named `emotion_cnn.py` using the `nano` command:

      
    nano emotion_cnn.py

    - Add the following script to the file:

      
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import torchvision.transforms as transforms
    from torch.utils.data import DataLoader, Dataset
    from PIL import Image
    import os

    class EmotionDataset(Dataset):
        def __init__(self, image_dir, transform=None):
            self.image_dir = image_dir
            self.transform = transform
            self.images = []
            self.labels = []
            self.emotions = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Sad': 4, 'Surprise': 5, 'Neutral': 6}

            for emotion in self.emotions:
                emotion_dir = os.path.join(image_dir, emotion)
                for img_file in os.listdir(emotion_dir):
                    self.images.append(os.path.join(emotion_dir, img
