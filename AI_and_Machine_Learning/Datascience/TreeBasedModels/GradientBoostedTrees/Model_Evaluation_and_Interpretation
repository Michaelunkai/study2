Model Eva tion and Interpretation
Let's make sure you understand how well our model is doing and what it means.

What We'll Do:
Understand Model Performance: Look at the Mean Squared Error (MSE) to see how accurate our model is.
Visualize Predictions: Plot the actual prices vs. the predicted prices to see how close our predictions are to the real values.
Step-by-Step Guide
Mean Squared Error (MSE):

MSE is a number that tells us how far our predictions are from the actual prices. Lower MSE means better predictions.
Plot Actual vs. Predicted Prices:

This plot will help us see if our model's predictions are close to the real house prices.
Full Code with Explanations
Calculate Mean Squared Error:
We already did this step, but we'll explain it again for clarity.
 
 
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
Explanation: This code calculates the average of the squared differences between the actual house prices and the predicted prices. If this number is low, it means our model is doing a good job.

Plot Actual vs. Predicted Prices:
 
 
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs. Predicted Prices')
plt.show()
Explanation:

plt.scatter(y_test, y_pred, color='blue'): This creates a scatter plot where each dot represents a house. The x-axis is the actual price, and the y-axis is the predicted price.
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2): This draws a red line where the actual price equals the predicted price. If all dots are close to this line, our predictions are good.
plt.xlabel('Actual Prices'), plt.ylabel('Predicted Prices'), plt.title('Actual vs. Predicted Prices'): These add labels and a title to our plot to make it easier to understand.
Full Code Together
 
 
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Example dataset
data = {
    'Size': [1500, 1700, 2000, 2200, 2500],
    'Bedrooms': [3, 3, 4, 4, 5],
    'Age': [10, 5, 20, 15, 5],
    'Price': [300000, 350000, 400000, 425000, 450000]
}
df = pd.DataFrame(data)

# Prepare data
X = df[['Size', 'Bedrooms', 'Age']]
y = df['Price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'subsample': [0.8, 0.9, 1.0]
}

# Initialize Grid Search
grid_search = GridSearchCV(estimator=GradientBoostingRegressor(random_state=42), 
                           param_grid=param_grid, 
                           cv=3, 
                           n_jobs=-1, 
                           scoring='neg_mean_squared_error')

# Fit Grid Search to the data
grid_search.fit(X_train, y_train)

# Get the best parameters and eva te the model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)

print(f'Best Parameters: {best_params}')
print(f'Mean Squared Error: {mse}')

# Extract Feature Importances
feature_importances = best_model.feature_importances_
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Visualize Feature Importances
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances in Gradient Boosting Model')
plt.gca().invert_yaxis()
plt.show()

# Plot Actual vs. Predicted Prices
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs. Predicted Prices')
plt.show()
Explanation:
Mean Squared Error:

Shows how far off the predictions are from the actual prices on average.
Plot Actual vs. Predicted Prices:

Helps you visually see how close your model's predictions are to the actual prices. If the dots are near the red line, the model is performing well.
