{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"intro-markdown","cell_type":"markdown","source":"# Advanced Video Game Sales Analysis for Three Questions\n\nThis notebook answers three advanced questions with multi-step analysis. Each question includes three blocks (cells) containing tables, graphs, and detailed insights.\n\nQuestions:\n1. **Which factors most significantly predict global sales?**\n2. **How does the popularity of a game evolve with age, and what is the longevity effect on sales?**\n3. **Can we cluster games into distinct groups based on their regional sales patterns?**","metadata":{}},{"id":"setup-cell","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\n# Load the dataset\ndf = pd.read_csv('Video_Games_Sales_as_at_22_Dec_2016.csv')\n\n# Convert Year_of_Release to numeric and drop rows with missing years\ndf['Year_of_Release'] = pd.to_numeric(df['Year_of_Release'], errors='coerce')\ndf = df.dropna(subset=['Year_of_Release'])\ndf['Year_of_Release'] = df['Year_of_Release'].astype(int)\n\n# For demonstration, if Critic_Score does not exist, create a synthetic column\nif 'Critic_Score' not in df.columns:\n    np.random.seed(42)\n    df['Critic_Score'] = np.random.randint(50, 100, size=len(df))\n\nprint('Setup complete. Data loaded and preprocessed.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:37.148023Z","iopub.execute_input":"2025-03-20T18:40:37.148384Z","iopub.status.idle":"2025-03-20T18:40:38.519Z","shell.execute_reply.started":"2025-03-20T18:40:37.148354Z","shell.execute_reply":"2025-03-20T18:40:38.515995Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2d48b983daf9>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Video_Games_Sales_as_at_22_Dec_2016.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Convert Year_of_Release to numeric and drop rows with missing years\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Video_Games_Sales_as_at_22_Dec_2016.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Video_Games_Sales_as_at_22_Dec_2016.csv'","output_type":"error"}],"execution_count":1},{"id":"430479a6-762d-4e3f-a5bc-2a17d2865aa4","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"q1-markdown","cell_type":"markdown","source":"## Question 1: Which factors most significantly predict global sales?\n\nIn this analysis we will first perform a correlation study and then build a regression model to determine which factors (e.g., Year of Release, Critic Score, etc.) predict Global Sales. Tables and graphs are used for insights.","metadata":{}},{"id":"q1-code-1","cell_type":"code","source":"# Q1 Block 1: Correlation Analysis\nnumeric_cols = ['Year_of_Release', 'Critic_Score', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\ncorr_matrix = df[numeric_cols].corr()\ncorr_table = pd.DataFrame(corr_matrix['Global_Sales'].sort_values(ascending=False))\nprint('Correlation of numeric factors with Global Sales:')\ndisplay(corr_table)\n\nplt.figure(figsize=(8,6))\nsns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\nplt.title('Correlation Matrix of Numeric Features')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.519636Z","iopub.status.idle":"2025-03-20T18:40:38.519989Z","shell.execute_reply":"2025-03-20T18:40:38.519844Z"}},"outputs":[],"execution_count":null},{"id":"q1-code-2","cell_type":"code","source":"# Q1 Block 2: Regression Model for Predicting Global Sales\n# Select features and target (we include Year_of_Release, Critic_Score, and Genre)\nfeatures = df[['Year_of_Release', 'Critic_Score', 'Genre']].dropna()\ntarget = df.loc[features.index, 'Global_Sales']\n\n# One-hot encode 'Genre'\nfeatures_encoded = pd.get_dummies(features, columns=['Genre'], drop_first=True)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\nprint('Regression model trained.')\n\n# Evaluate model performance\nr2_score = model.score(X_test, y_test)\nprint('R^2 Score on Test Set:', r2_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.521007Z","iopub.status.idle":"2025-03-20T18:40:38.521468Z","shell.execute_reply":"2025-03-20T18:40:38.521282Z"}},"outputs":[],"execution_count":null},{"id":"q1-code-3","cell_type":"code","source":"# Q1 Block 3: Display Regression Coefficients and Plot Predictions vs Actual\ncoefficients = pd.Series(model.coef_, index=X_train.columns)\nprint('Regression Coefficients:')\ndisplay(coefficients.sort_values(ascending=False))\n\n# Generate predictions for test set\npredictions = model.predict(X_test)\nresults = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\nprint('Sample Predictions:')\ndisplay(results.head(10))\n\n# Scatter plot of actual vs predicted values\nplt.figure(figsize=(8,6))\nplt.scatter(y_test, predictions, alpha=0.6, edgecolor='k')\nplt.xlabel('Actual Global Sales')\nplt.ylabel('Predicted Global Sales')\nplt.title('Actual vs Predicted Global Sales')\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.522224Z","iopub.status.idle":"2025-03-20T18:40:38.522682Z","shell.execute_reply":"2025-03-20T18:40:38.522486Z"}},"outputs":[],"execution_count":null},{"id":"q2-markdown","cell_type":"markdown","source":"## Question 2: How does the popularity of a game evolve with age, and what is the longevity effect on sales?\n\nIn this analysis we create a new column for game age, group games by age intervals, and study the average global sales per age group. Tables and graphs are used to reveal trends.","metadata":{}},{"id":"q2-code-1","cell_type":"code","source":"# Q2 Block 1: Calculate Game Age and Create Age Groups\ncurrent_year = 2025\ndf['Game_Age'] = current_year - df['Year_of_Release']\n\n# Define age bins (e.g., 0-5, 6-10, 11-15, 16-20, 21+)\nbins = [0, 5, 10, 15, 20, df['Game_Age'].max()]\nlabels = ['0-5', '6-10', '11-15', '16-20', '21+']\ndf['Age_Group'] = pd.cut(df['Game_Age'], bins=bins, labels=labels, right=False)\n\nprint('Sample of Game Age and Age Groups:')\ndisplay(df[['Name', 'Year_of_Release', 'Game_Age', 'Age_Group']].head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.523657Z","iopub.status.idle":"2025-03-20T18:40:38.524143Z","shell.execute_reply":"2025-03-20T18:40:38.523927Z"}},"outputs":[],"execution_count":null},{"id":"q2-code-2","cell_type":"code","source":"# Q2 Block 2: Create Table of Average Global Sales by Age Group\nage_group_sales = df.groupby('Age_Group')['Global_Sales'].mean().reset_index()\nage_group_sales.rename(columns={'Global_Sales': 'Avg_Global_Sales'}, inplace=True)\nprint('Average Global Sales by Game Age Group:')\ndisplay(age_group_sales)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.525223Z","iopub.status.idle":"2025-03-20T18:40:38.525681Z","shell.execute_reply":"2025-03-20T18:40:38.525494Z"}},"outputs":[],"execution_count":null},{"id":"q2-code-3","cell_type":"code","source":"# Q2 Block 3: Visualize the Effect of Game Age on Global Sales\nplt.figure(figsize=(10,6))\nsns.barplot(x='Age_Group', y='Global_Sales', data=df, palette='viridis', ci=None)\nplt.xlabel('Game Age Group (years)')\nplt.ylabel('Average Global Sales (millions)')\nplt.title('Longevity Effect on Global Sales by Age Group')\nplt.tight_layout()\nplt.show()\n\n# Optionally, also display a boxplot to show distribution within each group\nplt.figure(figsize=(10,6))\nsns.boxplot(x='Age_Group', y='Global_Sales', data=df, palette='Set2')\nplt.xlabel('Game Age Group (years)')\nplt.ylabel('Global Sales (millions)')\nplt.title('Sales Distribution by Game Age Group')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.526703Z","iopub.status.idle":"2025-03-20T18:40:38.527139Z","shell.execute_reply":"2025-03-20T18:40:38.526995Z"}},"outputs":[],"execution_count":null},{"id":"q3-markdown","cell_type":"markdown","source":"## Question 3: Can we cluster games into distinct groups based on their regional sales patterns?\n\nFor this analysis, we use regional sales columns to cluster games. We first prepare the data, then apply K-Means clustering, and finally use PCA for visualization. Tables and graphs help illustrate the clusters.","metadata":{}},{"id":"q3-code-1","cell_type":"code","source":"# Q3 Block 1: Data Preparation for Clustering\nregional_cols = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']\nregional_data = df[regional_cols].dropna()\n\n# Scale the regional sales data\nscaler = StandardScaler()\nregional_scaled = scaler.fit_transform(regional_data)\n\nprint('First 5 rows of scaled regional sales data:')\ndisplay(pd.DataFrame(regional_scaled, columns=regional_cols).head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.527976Z","iopub.status.idle":"2025-03-20T18:40:38.528313Z","shell.execute_reply":"2025-03-20T18:40:38.528183Z"}},"outputs":[],"execution_count":null},{"id":"q3-code-2","cell_type":"code","source":"# Q3 Block 2: Apply K-Means Clustering\nkmeans = KMeans(n_clusters=3, random_state=42)\nclusters = kmeans.fit_predict(regional_scaled)\n\n# Add the cluster labels back to the original dataframe (for the rows used)\ndf_cluster = df.loc[regional_data.index].copy()\ndf_cluster['Cluster'] = clusters\n\nprint('Cluster distribution:')\ndisplay(df_cluster['Cluster'].value_counts().reset_index().rename(columns={'index': 'Cluster', 'Cluster': 'Count'}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.529253Z","iopub.status.idle":"2025-03-20T18:40:38.529587Z","shell.execute_reply":"2025-03-20T18:40:38.529453Z"}},"outputs":[],"execution_count":null},{"id":"q3-code-3","cell_type":"code","source":"# Q3 Block 3: Visualize Clusters Using PCA\npca = PCA(n_components=2)\npca_components = pca.fit_transform(regional_scaled)\n\nplt.figure(figsize=(10,6))\nscatter = plt.scatter(pca_components[:, 0], pca_components[:, 1], c=clusters, cmap='Set1', edgecolor='k', s=50)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA Projection of Regional Sales Clusters')\nplt.legend(*scatter.legend_elements(), title='Cluster')\nplt.tight_layout()\nplt.show()\n\n# Create a table summarizing the mean regional sales per cluster\ncluster_summary = df_cluster.groupby('Cluster')[regional_cols].mean().reset_index()\nprint('Mean Regional Sales by Cluster:')\ndisplay(cluster_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:40:38.530624Z","iopub.status.idle":"2025-03-20T18:40:38.530998Z","shell.execute_reply":"2025-03-20T18:40:38.530833Z"}},"outputs":[],"execution_count":null}]}