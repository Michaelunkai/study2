# 2. Data Preparation
## 2.1 Collecting Data
Start by collecting data relevant to the problem you want to solve. Public datasets are a great resource, and websites like [Kaggle](https://www.kaggle.com/datasets) and the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) offer a wide variety of datasets.
## 2.2 Cleaning Data
Data cleaning is crucial for building a robust model. This includes handling missing values, removing duplicates, and correcting inconsistencies. Use tools like Pythonâ€™s `pandas` library for data manipulation and cleaning.
  
import pandas as pd
# Load your data
data = pd.read_ ('your_dataset. ')
# Check for missing values
print(data.isnull().sum())
# Fill missing values or drop rows/columns with missing data
data.fillna(method='ffill', inplace=True)
## 2.3 Feature Engineering
Feature engineering involves creating new features or modifying existing ones to improve model performance. Techniques include normalization, encoding categorical variables, and creating interaction terms.
  
from sklearn.preprocessing import StandardScaler, OneHotEncoder
# Standardize numerical features
scaler = StandardScaler()
data['normalized_feature'] = scaler.fit_transform(data[['numerical_feature']])
# Encode categorical features
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(data[['categorical_feature']])
