
The idea of neural networks running complex tasks like games is fascinating, and today, the answer to whether they can run DOOM is a resounding "Yes!" In a groundbreaking study titled GameNGen, Israeli researchers from Google have successfully trained a model based on Stable Diffusion that has "learned" the game DOOM and can simulate it in real-time. This means that while it feels like you're playing DOOM, the original game code isn't running at all. Instead, a generative model is producing each game frame in real-time based on the keys you're pressing, making it difficult to distinguish from the original game.

To simplify, Stable Diffusion is a model that has been trained to predict images based on text input from the userâ€”it is conditioned on the text and learns to generate a plausible image that matches the description. Analogously, the GameNGen model has been trained to predict the next frame in the game based on previous frames and the player's actions (mouse and keyboard). The researchers also fine-tune the model using a pre-trained Stable Diffusion model to improve its performance.

Beyond the cool concept, there are significant challenges in making such a system work, and the paper addresses some of these:

1. **Error Accumulation:** When the model generates frames by itself repeatedly (each frame being produced based on the previous frame output by the model), it tends to accumulate errors over time, leading to a noisy image that doesn't resemble the game after a few seconds. To counter this, the researchers added artificial noise to the recorded frames during training, teaching the model to correct its own noise and continue producing frames that look like the game.

2. **Decoder Accuracy:** The decoder tends to be inaccurate, especially in areas of the image where fine details are important, such as the HUD showing the player's health and other stats. To improve this, they performed separate fine-tuning of the decoder to push its outputs to more precisely resemble the game down to the pixel level, improving the accuracy of the details.

3. **Real-Time Performance:** Running the game in real-time is crucial, and generating images with Stable Diffusion can be slow. The researchers experimented with various parameters and found that four denoising steps of Stable Diffusion were sufficient to generate an image of DOOM's quality. This left them with 50ms to generate each frame, allowing for a reasonable 20 FPS, which is quite playable.

The videos demonstrate that while the system isn't perfect, and you might encounter strange phenomena like a monster being "forgotten" as dead and returning to life, these oddities can be viewed as "hallucinations," similar to errors we see in language models. Overall, this is a super cool piece of work that offers a glimpse into a future where we'll be using these models in increasingly creative ways.

**Image:** DOOM. Whether this is the original version or a frame generated by a Large Language Model (LLM) is already hard to tell...
