model = Sequential()
model.add(Dense(128, input_dim=1, activation='relu', kernel_initializer=HeNormal()))
for _ in range(10):
    model.add(Dense(128, activation='relu', kernel_initializer=HeNormal()))
model.add(Dense(1, activation='relu', kernel_initializer=HeNormal()))

model.compile(optimizer='adam', loss='mean_squared_error')

history = model.fit(x, y, epochs=100, verbose=0)

weights = model.layers[0].get_weights()[0]

plt.plot(weights)
plt.title('Weights of the first layer with ReLU and He Initialization')
plt. ow()
