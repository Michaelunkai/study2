 Implementing a Recurrent Neural Network (RNN) for Time Series Forecasting
In this step, we'll build and train a simple Recurrent Neural Network (RNN) using PyTorch for time series forecasting.

Install PyTorch:

pip install torch torchvision
Create a New Python Script:
Create a script for training an RNN using PyTorch. Name it pytorch_rnn.py.

nano pytorch_rnn.py
Write the Following Code in the Script:

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('time_series_data.csv')  # Replace with your time series data file
data = data['value'].values.reshape(-1, 1)  # Assuming 'value' column contains the time series data

# Prepare the data
scaler = MinMaxScaler(feature_range=(0, 1))
data = scaler.fit_transform(data)

def create_sequences(data, seq_length):
    xs, ys = [], []
    for i in range(len(data)-seq_length):
        x = data[i:i+seq_length]
        y = data[i+seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

seq_length = 10
X, y = create_sequences(data, seq_length)

# Convert to PyTorch tensors
X_tensor = torch.tensor(X, dtype=torch.float32)
y_tensor = torch.tensor(y, dtype=torch.float32)

# Define the RNN model
class RNN(nn.Module):
    def __init__(self, input_size=1, hidden_layer_size=50, output_size=1):
        super(RNN, self).__init__()
        self.hidden_layer_size = hidden_layer_size
        self.rnn = nn.RNN(input_size, hidden_layer_size, batch_first=True)
        self.linear = nn.Linear(hidden_layer_size, output_size)
        self.hidden_cell = torch.zeros(1, 1, self.hidden_layer_size)

    def forward(self, input_seq):
        rnn_out, self.hidden_cell = self.rnn(input_seq, self.hidden_cell)
        predictions = self.linear(rnn_out[:, -1])
        return predictions

model = RNN()
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Train the model
num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    optimizer.zero_grad()
    model.hidden_cell = torch.zeros(1, 1, model.hidden_layer_size)
    y_pred = model(X_tensor)
    loss = loss_function(y_pred, y_tensor)
    loss.backward()
    optimizer.step()

    if epoch % 10 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item()}')

# Make predictions
model.eval()
with torch.no_grad():
    y_pred = model(X_tensor)

# Transform back to original form
y_pred = scaler.inverse_transform(y_pred.numpy())
y_true = scaler.inverse_transform(y_tensor.numpy())

# Plot the results
plt.figure(figsize=(10, 6))
plt.plot(y_true, label='True Values')
plt.plot(y_pred, label='Predictions')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('RNN Time Series Forecasting')
plt.legend()
plt. ow()
Run the Script:

  pytorch_rnn.py
Explanation of  :
Epoch Loss: Displays the training loss at each epoch.
Time Series Plot: Visual representation comparing true values and RNN predictions.
