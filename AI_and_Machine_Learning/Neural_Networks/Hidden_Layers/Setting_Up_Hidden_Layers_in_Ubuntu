# Tutorial on Setting Up Hidden Layers in Ubuntu

This guide will walk you through the process of setting up and understanding hidden layers in neural networks using Python in Ubuntu. Hidden layers are a fundamental part of neural networks and play a crucial role in their ability to learn and make predictions.

## Prerequisites
1. Ubuntu OS installed.
2. Python 3.6 or higher installed.
3. Basic knowledge of Python and neural networks.

## Step 1: Install Necessary Libraries
First, we need to install the necessary libraries. We will use `pip` to install TensorFlow, which provides the necessary tools to create and train neural networks.

Open your terminal and run the following commands:

  
sudo apt update
sudo apt install python3-pip -y
pip3 install --upgrade pip
pip3 install tensorflow numpy

## Step 2: Understanding Hidden Layers
Hidden layers are intermediate layers between the input and output layers in a neural network. They are called "hidden" because their values are not observed in the training dataset. The hidden layers perform transformations on the inputs received from the input layer before passing them to the output layer.

## Step 3: Creating a Neural Network with Hidden Layers

Let's create a simple neural network with one hidden layer using TensorFlow.

### Example Code

Create a new Python file, `neural_network.py`, with the following content:

  
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Create a neural network model
model = Sequential()

# Add input layer
model.add(Dense(units=3, activation='relu', input_ ape=(2,)))

# Add hidden layer
model.add(Dense(units=5, activation='relu'))

# Add output layer
model.add(Dense(units=1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Print the model summary
model.summary()

### Explanation
1. **Sequential Model**: We use a `Sequential` model from TensorFlow's Keras API to create a linear stack of layers.
2. **Input Layer**: The first layer has 3 units with ReLU activation and expects input shape of (2,).
3. **Hidden Layer**: The hidden layer has 5 units with ReLU activation.
4. **Output Layer**: The output layer has 1 unit with sigmoid activation for binary classification.
5. **Compile Model**: The model is compiled with the Adam optimizer and binary crossentropy loss function.

## Step 4: Running the Neural Network

Run the script to create and display the model summary:

  
 3 neural_network.py

You should see the summary of the model, including the input layer, hidden layer, and output layer.

## Step 5: Training the Neural Network

To train the neural network, you need a dataset. For demonstration, let's create some dummy data.

Add the following code to `neural_network.py`:

  
import numpy as np

# Create dummy data
X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_train = np.array([0, 1, 1, 0])

# Train the model
model.fit(X_train, y_train, epochs=100)

# Evaluate the model
loss, accuracy = model.evaluate(X_train, y_train)
print(f'Loss: {loss}, Accuracy: {accuracy}')

### Explanation
1. **Dummy Data**: We create a simple dataset for XOR problem.
2. **Training**: The `fit` method is used to train the model for 100 epochs.
3. **Evaluation**: The `evaluate` method is used to compute the loss and accuracy of the model on the training data.

## Step 6: Running the Complete Script

Run the complete script to train and evaluate the neural network:

  
 3 neural_network.py

You should see the training progress and final loss and accuracy.

## Conclusion

You have successfully set up and trained a simple neural network with hidden layers in Ubuntu. Hidden layers are essential for neural networks to learn complex patterns in data. By experimenting with different numbers of hidden layers and units, you can improve the performance of your neural networks for various tasks.
