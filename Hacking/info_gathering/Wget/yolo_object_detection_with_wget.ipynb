{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+ku37HbFilrk7k8jvxa9X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"N6nwKs31_xnP","executionInfo":{"status":"ok","timestamp":1723725307862,"user_tz":-180,"elapsed":24089,"user":{"displayName":"מיכאל פדרו","userId":"11303103341006492289"}}},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","# Step 1: Download the YOLO model files using wget\n","os.system('wget https://pjreddie.com/media/files/yolov3.weights')\n","os.system('wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg')\n","os.system('wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names')\n","\n","# Step 2: Load the YOLO model and the class labels\n","net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n","with open(\"coco.names\", \"r\") as f:\n","    classes = [line.strip() for line in f.readlines()]\n","\n","layer_names = net.getLayerNames()\n","output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n","\n","# Set up colors for each class\n","colors = np.random.uniform(0, 255, size=(len(classes), 3))\n","\n","# Open the video capture\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","    # Read a frame from the video capture\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Get the dimensions of the frame\n","    height, width, channels = frame.shape\n","\n","    # Prepare the frame to pass through the network\n","    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","    net.setInput(blob)\n","    outs = net.forward(output_layers)\n","\n","    # Initialize lists for detected bounding boxes, confidences, and class IDs\n","    class_ids = []\n","    confidences = []\n","    boxes = []\n","\n","    # Loop over each detection\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.5:\n","                # Get the coordinates of the bounding box\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","\n","                # Get the top-left corner of the bounding box\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","\n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","                class_ids.append(class_id)\n","\n","    # Perform non-maxima suppression to remove overlapping bounding boxes\n","    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","\n","    # Draw bounding boxes and labels on the frame\n","    if len(indexes) > 0:\n","        for i in indexes.flatten():\n","            x, y, w, h = boxes[i]\n","            label = str(classes[class_ids[i]])\n","            confidence = confidences[i]\n","            color = colors[class_ids[i]]\n","\n","            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n","            cv2.putText(frame, f\"{label} {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","            print(f\"{label}: {confidence:.2f}\")\n","\n","    # Show the output frame\n","    cv2.imshow(\"Video Feed\", frame)\n","\n","    # If 'q' is pressed, break from the loop\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Release the video capture and close windows\n","cap.release()\n","cv2.destroyAllWindows()\n"]}]}