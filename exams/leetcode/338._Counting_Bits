### 338. Counting Bits

**Problem Description:**

Given an integer `n`, return an array `ans` of length `n + 1` such that for each `i` (0 <= i <= n), `ans[i]` is the number of 1's in the binary representation of `i`.

**Example 1:**
```
Input: n = 2
Output: [0,1,1]
Explanation:
0 --> 0
1 --> 1
2 --> 10
```

**Example 2:**
```
Input: n = 5
Output: [0,1,1,2,1,2]
Explanation:
0 --> 0
1 --> 1
2 --> 10
3 --> 11
4 --> 100
5 --> 101
```

**Constraints:**
- `0 <= n <= 10^5`

**Follow up:**
- It is very easy to come up with a solution with a runtime of `O(n log n)`. Can you do it in linear time `O(n)` and possibly in a single pass?
- Can you do it without using any built-in function (i.e., like `__builtin_popcount` in C++)?

### Explanation (Like I'm 12):

Imagine you have a list of numbers from 0 to `n`, and you want to count how many times the number 1 appears in the binary (0s and 1s) representation of each number. For example, the number 5 in binary is 101, and it has two 1s.

### Solution:

To solve this problem efficiently, we can use a dynamic programming approach where we build our answer array `ans` based on previously computed values. 

### Python Code:

```python
class Solution:
    def countBits(self, n: int) -> List[int]:
        ans = [0] * (n + 1)
        for i in range(1, n + 1):
            ans[i] = ans[i >> 1] + (i & 1)
        return ans
```

### Explanation of the Solution:

1. **Initialize Array:**
   - Create an array `ans` of size `n + 1` with all elements initialized to 0.

2. **Dynamic Programming Transition:**
   - For each number `i` from 1 to `n`:
     - The value of `ans[i]` can be derived from `ans[i >> 1]` (which is the count of 1s in the binary representation of `i` shifted right by 1 bit) plus `(i & 1)` (which checks if the least significant bit is 1).

3. **Return Result:**
   - Return the array `ans`.

### Example Walkthrough:

Let's take the example `n = 5`:

- Initialize `ans` as `[0, 0, 0, 0, 0, 0]`.
- For `i = 1`:
  - `1 >> 1` is `0` and `1 & 1` is `1`.
  - `ans[1] = ans[0] + 1 = 0 + 1 = 1`
  - `ans` becomes `[0, 1, 0, 0, 0, 0]`
- For `i = 2`:
  - `2 >> 1` is `1` and `2 & 1` is `0`.
  - `ans[2] = ans[1] + 0 = 1 + 0 = 1`
  - `ans` becomes `[0, 1, 1, 0, 0, 0]`
- For `i = 3`:
  - `3 >> 1` is `1` and `3 & 1` is `1`.
  - `ans[3] = ans[1] + 1 = 1 + 1 = 2`
  - `ans` becomes `[0, 1, 1, 2, 0, 0]`
- For `i = 4`:
  - `4 >> 1` is `2` and `4 & 1` is `0`.
  - `ans[4] = ans[2] + 0 = 1 + 0 = 1`
  - `ans` becomes `[0, 1, 1, 2, 1, 0]`
- For `i = 5`:
  - `5 >> 1` is `2` and `5 & 1` is `1`.
  - `ans[5] = ans[2] + 1 = 1 + 1 = 2`
  - `ans` becomes `[0, 1, 1, 2, 1, 2]`

This approach ensures that we compute the number of 1s in the binary representation of each number in linear time `O(n)`, making it very efficient.
