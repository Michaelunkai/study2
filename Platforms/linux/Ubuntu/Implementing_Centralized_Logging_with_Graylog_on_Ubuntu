### Step-by-Step Guide to Implement Centralized Logging with Graylog on Ubuntu

#### Step 1: Update System Packages
First, ensure your system is up to date.

  
sudo apt update
sudo apt upgrade -y

#### Step 2: Install Java
Graylog requires Java. Install OpenJDK:

  
sudo apt install openjdk-11-jre-headless -y

Verify the installation:

  
java -version

#### Step 3: Install MongoDB
Graylog uses MongoDB to store its configurations and metadata.

1. Import the MongoDB public GPG key:

  
wget -qO - https://www.mongodb.org/static/pgp/server-4.4.asc | sudo apt-key add -

2. Create a MongoDB source list file:

  
echo "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/4.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.4.list

3. Update the package database:

  
sudo apt update

4. Install MongoDB:

  
sudo apt install -y mongodb-org

5. Start and enable the MongoDB service:

  
sudo systemctl start mongod
sudo systemctl enable mongod

#### Step 4: Install Elasticsearch
Graylog uses Elasticsearch for storing and searching logs.

1. Import the Elasticsearch PGP key:

  
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -

2. Create the Elasticsearch source list file:

  
echo "deb https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-7.x.list

3. Update the package database:

  
sudo apt update

4. Install Elasticsearch:

  
sudo apt install elasticsearch

5. Start and enable the Elasticsearch service:

  
sudo systemctl start elasticsearch
sudo systemctl enable elasticsearch

6. Edit the Elasticsearch configuration file:

  
sudo nano /etc/elasticsearch/elasticsearch.yml

Replace the entire content of the file with:

  
# ======================== Elasticsearch Configuration =========================
#
# NOTE: Elasticsearch comes with reasonable defaults for most settings.
#       Before you set out to tweak and tune the configuration, make sure you
#       understand what are you trying to accomplish and the consequences.
#
# The primary way of configuring a node is via this file. This template lists
# the most important settings you may want to configure for a production cluster.
#
# Please consult the documentation for further information on configuration options:
# https://www.elastic.co/guide/en/elasticsearch/reference/index.html
#
# ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster:
#
cluster.name: graylog
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
#node.name: node-1
#
# Add custom attributes to the node:
#
#node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path.data: /var/lib/elasticsearch
#
# Path to log files:
#
path.logs: /var/log/elasticsearch
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
#bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# By default Elasticsearch is only accessible on localhost. Set a different
# address here to expose this node on the network:
#
network.host: localhost
#
# By default Elasticsearch listens for HTTP traffic on the first free port it
# finds starting at 9200. Set a specific HTTP port here:
#
http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when this node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
#discovery.seed_hosts: ["host1", "host2"]
#
# Bootstrap the cluster using an initial set of master-eligible nodes:
#
#cluster.initial_master_nodes: ["node-1", "node-2"]
discovery.type: single-node
# For more information, consult the discovery and cluster formation module documentation.
#
# ---------------------------------- Various -----------------------------------
#
# Require explicit names when deleting indices:
#
#action.destructive_requires_name: true
#
# ---------------------------------- Security ----------------------------------
#
#                                 *** WARNING ***
#
# Elasticsearch security features are not enabled by default.
# These features are free, but require configuration changes to enable them.
# This means that users donâ€™t have to provide credentials and can get full access
# to the cluster. Network connections are also not encrypted.
#
# To protect your data, we strongly encourage you to enable the Elasticsearch security features.
# Refer to the following documentation for instructions.
#
# https://www.elastic.co/guide/en/elasticsearch/reference/7.16/configuring-stack-security.html

Save and close the file.

Restart Elasticsearch to apply the changes:

  
sudo systemctl restart elasticsearch

#### Step 5: Install Graylog
1. Download and install the Graylog repository configuration:

  
wget https://packages.graylog2.org/repo/packages/graylog-4.2-repository_latest.deb
sudo dpkg -i graylog-4.2-repository_latest.deb

2. Update the package database:

  
sudo apt update

3. Install Graylog:

  
sudo apt install graylog-server -y

4. Generate a secret key for securing passwords:

  
pwgen -N 1 -s 96

Copy the generated key for later use.

5. Generate a password hash for the admin user:

  
echo -n yourpassword | sha256sum

Copy the resulting hash for later use.

6. Edit the Graylog configuration file:

  
sudo nano /etc/graylog/server/server.conf

Set the following parameters:

  
password_secret = <your_generated_secret_key>
root_password_ a2 = <your_generated_password_ha >

Set the Elasticsearch host:

  
elasticsearch_hosts = http://127.0.0.1:9200

Set the rest_listen_uri to:

  
rest_listen_uri = http://0.0.0.0:9000/api/

Set the web_listen_uri to:

  
web_listen_uri = http://0.0.0.0:9000/

Save and close the file.

7. Start and enable the Graylog service:

  
sudo systemctl start graylog-server
sudo systemctl enable graylog-server

#### Step 6: Access Graylog Web Interface
Open your web browser and navigate to:

http://<your_server_ip>:9000

Log in with the username `admin` and the password you hashed earlier.

#### Step 7: Configure Graylog Inputs
To start receiving logs, you need to configure inputs in the Graylog web interface.

1. Go to `System > Inputs`.
2. Select the input type you need (e.g., Syslog UDP) and click `Launch new input`.
3. Fill in the required details and start the input.

Your Graylog server is now set up and ready to aggregate logs from different sources. You can further refine your setup by configuring additional inputs, streams, and dashboards as per your requirements.
